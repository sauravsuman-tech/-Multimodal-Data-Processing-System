# ğŸ§  Multimodal Data Processing System

A **FastAPI + Streamlit** based system that processes and searches across **text, image, audio, and video** files using AI.  
It performs **OCR**, **speech-to-text transcription**, **chunking**, **embedding generation**, and **semantic search** â€” all inside one unified interface.

---

## ğŸš€ Features

âœ… Supports multiple input types:

| File Type | Supported Formats | Processing Type |
|------------|------------------|-----------------|
| **Text** | `.pdf`, `.docx`, `.pptx`, `.md`, `.txt` | Extracts readable text |
| **Image** | `.png`, `.jpg`, `.jpeg` | OCR using Tesseract |
| **Audio / Video** | `.mp3`, `.mp4`, `.wav`, `.m4a`, `.aac`, `.flac` | Speech-to-text using Whisper |
| **YouTube** | YouTube URLs | Downloads & transcribes |

âœ… Chunk-based text segmentation  
âœ… Vector embeddings using `SentenceTransformer` + `FAISS`  
âœ… Search across multimodal content  
âœ… Ask questions via Streamlit UI  
âœ… Ready for Gemini or any LLM integration  

---

## ğŸ§© System Architecture

ğŸ“‚ Multimodal Data Processing System/
â”‚
â”œâ”€ app/
â”‚ â”œâ”€ main.py # FastAPI backend (file upload, query)
â”‚ â”œâ”€ parsers.py # Extracts text from all formats
â”‚ â”œâ”€ ocr.py # OCR using pytesseract
â”‚ â”œâ”€ audio.py # Handles YouTube/audio transcription
â”‚ â”œâ”€ chunker.py # Splits text into chunks for embeddings
â”‚ â”œâ”€ embed_store.py # Manages FAISS vector store
â”‚ â”œâ”€ llm_client.py # LLM (Gemini/OpenAI) integration
â”‚
â”œâ”€ ui_streamlit.py # Streamlit frontend (user interface)
â”œâ”€ requirements.txt # Python dependencies
â””â”€ README.md # Documentation

yaml
Copy code

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/multimodal-data-processing-system.git
cd multimodal-data-processing-system/app
2ï¸âƒ£ Create Virtual Environment
bash
Copy code
python -m venv myenv
myenv\Scripts\activate       # On Windows
# or
source myenv/bin/activate    # On macOS/Linux
3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt
ğŸ§  Run the Application
Step 1: Start FastAPI Backend
bash
Copy code
cd app
python main.py
âœ… Backend will start at:

arduino
Copy code
http://localhost:8000
Step 2: Start Streamlit Frontend
In a new terminal (while backend is running):

bash
Copy code
streamlit run ui_streamlit.py
âœ… Streamlit app will open at:

arduino
Copy code
http://localhost:8501
ğŸ§ª How It Works
1ï¸âƒ£ Upload Files

Upload one or more files (PDF, DOCX, PPTX, TXT, MD, PNG, JPG, MP3, MP4, etc.)

FastAPI reads and parses the content using:

PyPDF2, python-docx, python-pptx for text

pytesseract for OCR

whisper for speech-to-text

Each file is chunked into small segments for efficient search.

The chunks are converted into vector embeddings using SentenceTransformer (MiniLM).

Embeddings are stored in a FAISS vector index.

2ï¸âƒ£ Ask Questions

Enter a natural-language question in the Streamlit UI.

The system searches the FAISS vector store for the most relevant chunks.

Optionally, the system can use Gemini (or any LLM) for a more contextual answer.

3ï¸âƒ£ Get Answers

The UI displays the answer and the top matching content snippets.

ğŸ“Š Example Usage
Upload files
â†’ Choose a resume.pdf and a meeting.mp3
â†’ Click "Upload"

Ask a question
â†’ â€œWhat did we discuss about pricing?â€
â†’ Get AI-powered answers extracted from audio transcription and text files.

ğŸ§° Tech Stack
Layer	Technology
Backend	FastAPI
Frontend	Streamlit
Embeddings	Sentence Transformers (all-MiniLM-L6-v2)
Vector Store	FAISS
OCR	pytesseract
Speech-to-Text	Whisper
LLM	Gemini (stubbed) / OpenAI-compatible
Others	PyPDF2, python-docx, pydub, yt-dlp, markdown